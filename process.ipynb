{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1328f5c7",
   "metadata": {},
   "source": [
    "#### Set program variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945de155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# We know the last year of data available is 2023\n",
    "last_year = 2023\n",
    "page_url = \"https://www.ers.usda.gov/data-products/fruit-and-vegetable-prices\"\n",
    "data_dir = \"/temp-output-directory/alternative/usda/fruitandvegetables/\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "def normalize(x):\n",
    "    '''We need to normalize file names for consistent sorting.'''\n",
    "    return x.lower().replace('-', '_').replace(' ', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a0d3ff",
   "metadata": {},
   "source": [
    "#### Data Downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9184e94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# Scrape the USDA page to find all XLSX, and ZIP download links\n",
    "print(f\"Scraping {page_url}...\")\n",
    "response = requests.get(page_url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "download_links = []\n",
    "for a in soup.find_all('a', href=True):\n",
    "    href = a['href'].lower()\n",
    "    # Find all links that end with .xlsx, or .zip\n",
    "    for ext in ['.zip', '.xlsx']:\n",
    "        if href.endswith(ext) or f'{ext}?' in href:\n",
    "            download_links.append(a['href'])\n",
    "            break\n",
    "\n",
    "print(f\"Found {len(download_links)} files to download\")\n",
    "\n",
    "# Download each file\n",
    "downloaded_files = []\n",
    "for link in download_links:\n",
    "    # Construct full URL\n",
    "    if not link.startswith('http'):\n",
    "        file_url = page_url[:25] + link\n",
    "    else:\n",
    "        file_url = link\n",
    "    \n",
    "    extract_dir = \"extracted\"\n",
    "    os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "    # Extract filename from URL\n",
    "    filename = normalize(file_url.split('/')[-1].split('?')[0])\n",
    "    \n",
    "    # Save XLSX files within extracted folder where we will also extract ZIP contents\n",
    "    if filename.endswith('.xlsx'):\n",
    "        index = filename.find('average')\n",
    "        filename = f\"extracted/{filename[:index-1]}_{last_year}.xlsx\"\n",
    "\n",
    "    print(f\"\\nDownloading: {filename}\")\n",
    "    print(f\"URL: {file_url}\")\n",
    "    \n",
    "    try:\n",
    "        file_response = requests.get(file_url)\n",
    "        \n",
    "        if file_response.status_code == 200:\n",
    "            # Save to file\n",
    "            with open(filename, \"wb\") as f:\n",
    "                f.write(file_response.content)\n",
    "                if filename.endswith('.zip'):\n",
    "                    print(f\"\\n{'='*60}\")\n",
    "                    print(f\"Processing: {filename}\")\n",
    "                    print(f\"{'='*60}\")\n",
    "                    try:\n",
    "                        with ZipFile(filename, 'r') as zip_ref:\n",
    "                            # Extract XLSX files to a temporary directory\n",
    "                            files = [zip_ref.extract(f, extract_dir) \n",
    "                                for f in zip_ref.namelist() if f.endswith('.xlsx')]\n",
    "                            print(f\"XLSX files in archive: {files}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing ZIP file: {e}\")\n",
    "            \n",
    "            print(f\"✓ Success - {len(file_response.content)} bytes\")\n",
    "            downloaded_files.append(filename)\n",
    "        else:\n",
    "            print(f\"✗ Failed - Status code: {file_response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error: {e}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Download complete: {len(downloaded_files)} files saved\")\n",
    "print(f\"{'='*60}\")\n",
    "for f in downloaded_files:\n",
    "    print(f\"  • {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4928e08",
   "metadata": {},
   "source": [
    "#### Data Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb34cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from itertools import groupby\n",
    "\n",
    "def get_hash(x):\n",
    "    x = normalize(x)\n",
    "    return x[:x.find(re.search(r'(\\d{4})', x).group(1))-1]\n",
    "    \n",
    "allfiles = sorted([x for x in os.listdir('extracted') if x.endswith('.xlsx')], key=normalize)\n",
    "files_by_symbol = groupby(allfiles, key=get_hash)\n",
    "data_by_symbol = {}\n",
    "for symbol, files in files_by_symbol:\n",
    "    print(f\"Processing symbol: {symbol}\")\n",
    "    data = []\n",
    "    for file_name in files:\n",
    "        year = re.search(r'(\\d{4})', file_name).group(1)\n",
    "        wb = openpyxl.load_workbook(os.path.join('extracted', file_name), data_only=True)\n",
    "        for row in wb._sheets[0]:\n",
    "            values = [cell.value for cell in row]\n",
    "            if not any(x for x in values if isinstance(x, float)):\n",
    "                continue\n",
    "            if values[0][-1].isdigit():\n",
    "                values[0] = values[0][:-1]\n",
    "            line = f'{int(year)+1}0101,' + ','.join(normalize(str(v).strip()) for v in values)\n",
    "            data.append(line)\n",
    "    with open(os.path.join(data_dir, f'{symbol}.csv'), 'w') as f:\n",
    "        f.write('\\n'.join(data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
